use rand::{rngs::StdRng, Rng, SeedableRng};

#[derive(Debug, PartialEq)]
pub struct LayerGrads {
    pub weight_grads: Vec<f64>,
    pub input_grads: Vec<f64>,
}

impl LayerGrads {
    fn new(weight_grads: Vec<f64>, input_grads: Vec<f64>) -> Self {
        Self {
            weight_grads,
            input_grads,
        }
    }
}

pub struct Layer {
    inputs: usize,
    outputs: usize,
    weights: Vec<f64>,
    last_inputs: Vec<f64>,
}

impl Layer {
    pub fn new(inputs: usize, outputs: usize) -> Self {
        const SEED: u64 = 410;
        const SCALE: f64 = 0.2;
        let mut rng = StdRng::seed_from_u64(SEED);
        let mut weights = vec![0.0; inputs * outputs];
        weights.fill_with(|| SCALE * rng.gen_range(-1.0..=1.0));
        Self {
            weights,
            last_inputs: Vec::new(),
            inputs,
            outputs,
        }
    }

    pub fn forward(&mut self, inputs: Vec<f64>) -> Vec<f64> {
        let batch_size = inputs.len() / self.inputs;
        let mut outputs = vec![0.0; batch_size * self.outputs];
        for b in 0..batch_size {
            for o in 0..self.outputs {
                let mut sum = 0.0;
                for i in 0..self.inputs {
                    sum += inputs[b * self.inputs + i]
                        * self.weights[self.outputs * i + o];
                }
                outputs[b * self.outputs + o] = sum;
            }
        }
        self.last_inputs = inputs;
        outputs
    }

    pub fn backward(&self, grads: Vec<f64>) -> LayerGrads {
        let mut weight_grads = vec![0.0; self.inputs * self.outputs];

        let batch_size = self.last_inputs.len() / self.inputs;
        let mut input_grads = vec![0.0; batch_size * self.inputs];

        for b in 0..batch_size {
            for i in 0..self.inputs {
                for o in 0..self.outputs {
                    weight_grads[i * self.outputs + o] += (grads
                        [b * self.outputs + o]
                        * self.last_inputs[b * self.inputs + i])
                        / batch_size as f64;
                    input_grads[b * self.inputs + i] += grads
                        [b * self.outputs + o]
                        * self.weights[i * self.outputs + o];
                }
            }
        }
        LayerGrads::new(weight_grads, input_grads)
    }

    pub fn apply_gradients(&mut self, grads: Vec<f64>) {
        for (i, w) in self.weights.iter_mut().enumerate() {
            const STEP_SIZE: f64 = 0.01;
            *w -= STEP_SIZE * grads[i];
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_backward() {
        let mut layer = Layer::new(20, 10);
        const SEED: u64 = 410;
        let mut rng = StdRng::seed_from_u64(SEED);
        let mut weights = vec![0.0; 20];
        weights.fill_with(|| rng.gen_range(-1.0..=1.0));
        layer.forward(weights);
        let got = layer.backward(vec![0.5; 10]);

        let want = LayerGrads {
            weight_grads: vec![
                0.38018418347037186,
                0.38018418347037186,
                0.38018418347037186,
                0.38018418347037186,
                0.38018418347037186,
                0.38018418347037186,
                0.38018418347037186,
                0.38018418347037186,
                0.38018418347037186,
                0.38018418347037186,
                -0.292390554305705,
                -0.292390554305705,
                -0.292390554305705,
                -0.292390554305705,
                -0.292390554305705,
                -0.292390554305705,
                -0.292390554305705,
                -0.292390554305705,
                -0.292390554305705,
                -0.292390554305705,
                -0.3953046625183658,
                -0.3953046625183658,
                -0.3953046625183658,
                -0.3953046625183658,
                -0.3953046625183658,
                -0.3953046625183658,
                -0.3953046625183658,
                -0.3953046625183658,
                -0.3953046625183658,
                -0.3953046625183658,
                -0.43928807748670073,
                -0.43928807748670073,
                -0.43928807748670073,
                -0.43928807748670073,
                -0.43928807748670073,
                -0.43928807748670073,
                -0.43928807748670073,
                -0.43928807748670073,
                -0.43928807748670073,
                -0.43928807748670073,
                0.012274764554708661,
                0.012274764554708661,
                0.012274764554708661,
                0.012274764554708661,
                0.012274764554708661,
                0.012274764554708661,
                0.012274764554708661,
                0.012274764554708661,
                0.012274764554708661,
                0.012274764554708661,
                -0.4701958583489785,
                -0.4701958583489785,
                -0.4701958583489785,
                -0.4701958583489785,
                -0.4701958583489785,
                -0.4701958583489785,
                -0.4701958583489785,
                -0.4701958583489785,
                -0.4701958583489785,
                -0.4701958583489785,
                0.2157223866630803,
                0.2157223866630803,
                0.2157223866630803,
                0.2157223866630803,
                0.2157223866630803,
                0.2157223866630803,
                0.2157223866630803,
                0.2157223866630803,
                0.2157223866630803,
                0.2157223866630803,
                0.288118133310979,
                0.288118133310979,
                0.288118133310979,
                0.288118133310979,
                0.288118133310979,
                0.288118133310979,
                0.288118133310979,
                0.288118133310979,
                0.288118133310979,
                0.288118133310979,
                -0.3727042143332935,
                -0.3727042143332935,
                -0.3727042143332935,
                -0.3727042143332935,
                -0.3727042143332935,
                -0.3727042143332935,
                -0.3727042143332935,
                -0.3727042143332935,
                -0.3727042143332935,
                -0.3727042143332935,
                0.018049965532817347,
                0.018049965532817347,
                0.018049965532817347,
                0.018049965532817347,
                0.018049965532817347,
                0.018049965532817347,
                0.018049965532817347,
                0.018049965532817347,
                0.018049965532817347,
                0.018049965532817347,
                0.06418736262587343,
                0.06418736262587343,
                0.06418736262587343,
                0.06418736262587343,
                0.06418736262587343,
                0.06418736262587343,
                0.06418736262587343,
                0.06418736262587343,
                0.06418736262587343,
                0.06418736262587343,
                0.1819296355501877,
                0.1819296355501877,
                0.1819296355501877,
                0.1819296355501877,
                0.1819296355501877,
                0.1819296355501877,
                0.1819296355501877,
                0.1819296355501877,
                0.1819296355501877,
                0.1819296355501877,
                -0.2997148848088573,
                -0.2997148848088573,
                -0.2997148848088573,
                -0.2997148848088573,
                -0.2997148848088573,
                -0.2997148848088573,
                -0.2997148848088573,
                -0.2997148848088573,
                -0.2997148848088573,
                -0.2997148848088573,
                -0.35068646591286057,
                -0.35068646591286057,
                -0.35068646591286057,
                -0.35068646591286057,
                -0.35068646591286057,
                -0.35068646591286057,
                -0.35068646591286057,
                -0.35068646591286057,
                -0.35068646591286057,
                -0.35068646591286057,
                0.46691566342967605,
                0.46691566342967605,
                0.46691566342967605,
                0.46691566342967605,
                0.46691566342967605,
                0.46691566342967605,
                0.46691566342967605,
                0.46691566342967605,
                0.46691566342967605,
                0.46691566342967605,
                -0.09143315545589059,
                -0.09143315545589059,
                -0.09143315545589059,
                -0.09143315545589059,
                -0.09143315545589059,
                -0.09143315545589059,
                -0.09143315545589059,
                -0.09143315545589059,
                -0.09143315545589059,
                -0.09143315545589059,
                -0.2640128477274856,
                -0.2640128477274856,
                -0.2640128477274856,
                -0.2640128477274856,
                -0.2640128477274856,
                -0.2640128477274856,
                -0.2640128477274856,
                -0.2640128477274856,
                -0.2640128477274856,
                -0.2640128477274856,
                0.46265596888927485,
                0.46265596888927485,
                0.46265596888927485,
                0.46265596888927485,
                0.46265596888927485,
                0.46265596888927485,
                0.46265596888927485,
                0.46265596888927485,
                0.46265596888927485,
                0.46265596888927485,
                0.3835074412875481,
                0.3835074412875481,
                0.3835074412875481,
                0.3835074412875481,
                0.3835074412875481,
                0.3835074412875481,
                0.3835074412875481,
                0.3835074412875481,
                0.3835074412875481,
                0.3835074412875481,
                0.23144508795687802,
                0.23144508795687802,
                0.23144508795687802,
                0.23144508795687802,
                0.23144508795687802,
                0.23144508795687802,
                0.23144508795687802,
                0.23144508795687802,
                0.23144508795687802,
                0.23144508795687802,
            ],
            input_grads: vec![
                -0.21110678669221727,
                0.15695876116686883,
                0.2195892424012807,
                0.10266694405234615,
                -0.14560724587239268,
                0.20650774517199558,
                -0.20308572281886234,
                -0.14961062911265802,
                0.3021367476144003,
                0.1861185098760274,
                -0.016331605350147212,
                -0.11812773226639918,
                0.10578757439240896,
                -0.2322223067190178,
                -0.3550241674280954,
                0.03589887170871607,
                -0.003407476155169009,
                -0.11704609627296109,
                -0.12524127307294589,
                -0.09993704666527364,
            ],
        };
        assert_eq!(got, want);
    }
}
